## Introduction

As machine learning techniques have become more popular in biomedicine, a number of unique challenges have arisen that require creative solutions.
For various reasons including cost and experimental throughput, biomedical datasets often contain more input predictors than data samples [@doi:10.1109/JPROC.2015.2494198; @arxiv:1611.09340].
For example, a genetic study may include many single nucleotide polymorphisms (SNPs) in few patients, or a gene expression study may profile the expression of many genes in a handful of samples.
Thus, if the input data are highly structured, it may be difficult to learn the correlation structure of the predictors directly from the data.
This stands in contrast to non-biological applications of machine learning, where one might fit a model on millions of images [@doi:10.1109/CVPR.2009.5206848] or tens of thousands of documents [@doi:10.1016/B978-1-55860-377-6.50048-7].

In addition, biological knowledge can take many forms.
Examples include binary pathway databases, gene interaction networks, and knowledge hierarchies such as the Gene Ontology [@doi:10.1093/nar/gky1055].
Incorporating these resources in machine learning models can be helpful in distinguishing signal from noise and imputing missing data [@doi:10.1038/nrg.2017.38].
However, there is frequently no canonical way to encode these structures as real-valued features, which means modelers must be creative when deciding how to encode the relevant biological knowledge in the model.

In this review, we address approaches to learning from structured biomedical data.
One example of a commonly used approach is adding a regularization term to the model's loss function to reflect a biological desideratum.
We also consider other examples in this review, such as deep learning approaches that operate on genomic sequences, or neural network architectures that are constrained based on biological knowledge.

