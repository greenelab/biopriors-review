## Introduction

As machine learning techniques have gained popularity in biomedicine, unique challenges have arisen that require creative solutions.
Biological knowledge can take many forms, including genomic sequences, pathway databases, gene interaction networks, and knowledge hierarchies such as the Gene Ontology [@doi:10.1093/nar/gky1055].
Incorporating these resources in machine learning models can be helpful in distinguishing signal from noise [@doi:10.1038/nrg.2017.38], and in facilitating interpretation of model predictions [@doi:10.1016/j.cell.2018.05.056].
However, there is often no canonical way to encode these structures as real-valued predictors, which means modelers must be creative when deciding how to encode the relevant biological knowledge in the model.

In addition, for various reasons including cost and experimental throughput, biomedical datasets often contain more input predictors than data samples [@doi:10.1109/JPROC.2015.2494198; @arxiv:1611.09340].
For example, a genetic study may genotype millions of single nucleotide polymorphisms (SNPs) in hundreds of patients, or a gene expression study may profile the expression of thousands of genes in only a handful of samples.
Thus, if the input data are highly structured, it may be difficult to model the correlation structure of the predictors directly from the data.
This stands in contrast to non-biological applications of machine learning, where one might fit a model on millions of images [@doi:10.1109/CVPR.2009.5206848] or tens of thousands of documents [@doi:10.1016/B978-1-55860-377-6.50048-7].

In this review, we survey approaches to learning from structured biomedical data.
One class of commonly used approaches involves adding a regularization term to the model's loss function to reflect a biological desideratum.
We also consider other examples in this review, such as deep learning approaches that operate on genomic sequences, and neural network architectures that are constrained based on biological knowledge.

